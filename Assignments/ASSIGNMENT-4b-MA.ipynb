{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "6158d020",
   "metadata": {},
   "source": [
    "# Assignment 4 MA Part B\n",
    "\n",
    "\n",
    "\n",
    "**<mark>Tip: This assignment is less guided than the assignments you have worked on so far. Please start early and use the classes (and piazza) to ask for clarification if necessary. </mark>**\n",
    "\n",
    "## A corpus of TED talks and their translations\n",
    "\n",
    "In this assignment, you are going to work with a corpus of transcribed TED talks (English) and their translations into other languages. The resource was developed by \n",
    "\n",
    "\n",
    "The resource is called WIT3 - acronym for Web Inventory of Transcribed and Translated Talks.\n",
    "\n",
    "\n",
    "In part I of the assignment, you are going to analyze the original talks. In part II, you are going to explore the translations. \n",
    "\n",
    "The learning goals of this assginment are the following:\n",
    "\n",
    "* Become comfortable with extracting information from xml\n",
    "* Learn how to explore a corpus consisting of multiple files\n",
    "* Lean how to map information accross mutliple files\n",
    "* Take the first steps in indepdently structuring code\n",
    "\n",
    "\n",
    "If you are interesed in learning more about the resource and what it is used for, you can check the following paper:\n",
    "\n",
    "\n",
    "M. Cettolo, C. Girardi, and M. Federico. 2012. WIT3: Web Inventory of Transcribed and Translated Talks.\n",
    "In Proc. of EAMT, pp. 261-268, Trento, Italy [pdf].\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba374cdf",
   "metadata": {},
   "source": [
    "# Step 1: Prepare the data and understand the corpus structure \n",
    "\n",
    "**1.) Download**\n",
    "\n",
    "Please go to the following url: https://wit3.fbk.eu/2018-01-b\n",
    "\n",
    "Download the 2018 dataset by clicking on the link in the text and then download the shared file. \n",
    "\n",
    "Please the download in the Data directory (`../Data/`). Create a new folder called `ted-talks` and move the download there. Unpack it (should work by double-clicking on it). \n",
    "\n",
    "\n",
    "The corpus you downloaded contains multiple releases of the data. You data should be at `../Data/ted-talks/FILTERED_xml/`.\n",
    "\n",
    "\n",
    "Please run the cell below to check if you have the data. You should see a long list of files ending in .xml starting with:\n",
    "\n",
    "```\n",
    "ted_af.xml\n",
    "ted_am.xml\n",
    "ted_ar.xml\n",
    "ted_arq.xml\n",
    "ted_art-x-bork.xml\n",
    "ted_as.xml\n",
    "```\n",
    "\n",
    "\n",
    "\n",
    "The directories starting with 'xml' contain different versions of the data. We will focus on the most recent version of the data in the directory `xml/`. Feel free to remove the remaining two directories. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a2a88ab",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# mac os/linux:\n",
    "%ls ../Data/ted-talks/FILTERED_xml/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f495c5ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# windows (please adapt if necessary in this and all following cells): \n",
    "%ls ..\\Data\\ted-talks\\FILTERED_xml\\"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6909da7c",
   "metadata": {},
   "source": [
    "**2.) Understanding the structure of the corpus** \n",
    "\n",
    "Consider the list of files you printed above. You will see that all file names follow the same convention: `ted-[language abbreviation].xml` The corpus you just downloaded contains Ted talks (originally given in English) translated to other languages. The file for one language (e.g. `ted_nl.xml`) contains all translations into a target language (e.g. Dutch). You can find the original English talks in `ted_en.xml`)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "512fd5a1",
   "metadata": {},
   "source": [
    "**3.) Understanding the xml structure and finding translations of the same text**\n",
    "\n",
    "To extract a translation of a particular text, we have to look into the xml structure of a single file. Open the xml file with the translations into Dutch in an editor (e.g. atom). \n",
    "\n",
    "\n",
    "Try to get a global idea of the structure. The following questions can help to guide you:\n",
    "\n",
    "(1) How many different talks does the file contain? (Hint: Scroll all the way down.)\n",
    "\n",
    "(2) Which tags indicate new talks? \n",
    "\n",
    "(3) Where do you find meta-information about a talk? Where do you find the translated text of the talk? Where do you find the transcription of the video? \n",
    "\n",
    "(4) Where do you find the identifier of the talk? Hint: look for a tag called 'talkid'. You can use this information to match translations with original talks. \n",
    "\n",
    "Tip: load one file and explore the information given about one talk using lxml.etree in python. You can use the code below to get started.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71813cf9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from lxml import etree as et"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8286de89",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test = '../Data/ted-talks/FILTERED_xml/ted_nl.xml'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dfa10f7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tree = et.parse(test)\n",
    "root = tree.getroot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccb79848",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# The language is again provided in an attribute of the root:\n",
    "print(root.attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0df142e7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Explore the first layer of xml tags:\n",
    "for ch in root.getchildren():\n",
    "    print(ch.tag)\n",
    "# Tip: Is there more information you can access at this point? Tip: explore text and attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8825e53",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Explore a single talk\n",
    "\n",
    "## First extract all talks (hint: each file capture one talk)\n",
    "\n",
    "talks = root.findall('file')\n",
    "print(len(talks))\n",
    "\n",
    "## Pick one talk to explore\n",
    "test_talk = talks[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78f6134b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for ch in test_talk.getchildren():\n",
    "    print(ch.tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e270dc9c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# explore the meta information:\n",
    "\n",
    "head = test_talk.find('head')\n",
    "\n",
    "for ch in head.getchildren():\n",
    "    print(ch.tag)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "681a85b3",
   "metadata": {},
   "source": [
    "# Assignment\n",
    "\n",
    "In this assignment, you will write code to explore the dataset. For instance, you will answer questions such as \n",
    "\n",
    "* How many talks are there in total? How many languages do the translations cover?\n",
    "* What is the oldest/latest talk?\n",
    "* Which speaker is most widely translated?\n",
    "\n",
    "Don't worry if you don't know how to solve these questions just now. You will start by working on the English talks (i.e. a single xml file). This will give you a feeling for the xml structure. You will write a number of small functions to extract information and compare talks. You should then be able to reuse your functions to explore the translations (i.e. work on multiple xml files). \n",
    "\n",
    "**Please write doc strings for all of your functions to get full points.**\n",
    "\n",
    "## Part I: Analyze the original English talks\n",
    "\n",
    "This part of the assignment only requires you to analyze the content of the xml file containing the original talks (in English). \n",
    "\n",
    "Create a python scipt which give you the following information:\n",
    "\n",
    "* What is the longest talk (in terms of word count), what is the shortest talk (in terms of word count), what is the average word count? (id and title, numbers) (`find_wc`)? \n",
    "* Oldest and latest talk (id and title, dates) (`find_date`)\n",
    "* Is there a speaker with multiple talks? (function: `find_speaker`)\n",
    "* How many English talks are there in total? (No function required, you can simply use a built-in function on the list of all English talk elements.)\n",
    "\n",
    "\n",
    "Tip: There are inconsistencies in the data leading to talks without text. Please exclude these talks from your analysis. \n",
    "\n",
    "Please use informative print statements to answer the questions listed above. \n",
    "\n",
    "Each of these aspects should be covered by a function (you can of course define additional helper functions and call them in the functions described below). The functions should be named as follows and take the input and return the output described below:\n",
    "\n",
    "* `find_wc`: \n",
    "    * input: list of all talk elements (positional), length (longest/shortest, keyword argument)\n",
    "    * output: \n",
    "        * title(s) of the longest/shortest talk (number of words) (list)\n",
    "        * id(s) of the longest/shortest talk (list)\n",
    "        * word count of the longest/shortest talk\n",
    "        * mean word count of all talks\n",
    "* `find_date`:\n",
    "    * input: list of all talk elements (positional), time (oldest/newest, keyword argument)\n",
    "    * output: \n",
    "        * title(s) of the oldest/newest talk\n",
    "        * id(s) of the oldest/newest talk\n",
    "* `find_speaker`:\n",
    "    * input: list of talk elemenets (position)\n",
    "    * output: dict mapping speakers with more than one talk to their talks (tuple of talk title and id)\n",
    "\n",
    "**Note:** *The output of all of your functions should contain the talk title **and** id of the talk. The reason for this is that we use the id information in Part II of the assignment to match talks with their translations. (We cannot use the titles, as the tiles have also been translated. We will thus need ids to find translation pairs.*\n",
    "\n",
    "Your script should be called `ted_english_analysis.py` and execute all functions. \n",
    "\n",
    "**Code structure**\n",
    "\n",
    "The script should only contain the functions listed above. If you use helper functions (highly recommended, see tips below), please put them in a script called `utils.py` and import them in the script called `ted_english_analysis.py`. \n",
    "\n",
    "You can use a main function (main()), which calls all functions (not compulsory). \n",
    "\n",
    "**Informative print statements**\n",
    "\n",
    "Please use print statements to indicate what the function outputs refer to. Please don't forget to print the total number of talks. We recommend using f-strings, for instance:\n",
    "\n",
    "```\n",
    "n_talks = len(talks)\n",
    "print('In total, there are {n_talks} English Ted talks in the dataset.')\n",
    "\n",
    "The script should be called `ted_english_analysis.py` and execute all functions when called from the command line. Add print statements so the output can be interpreted. For example, you the script should print: \n",
    "```\n",
    "\n",
    "```\n",
    "The total number of English talks is: [total number]\n",
    "\n",
    "Talk length: \n",
    "Longest talk: [title] (id: [id])\n",
    "Shortest talk: [title] (id: [id])\n",
    "Mean word count: [mean word count]\n",
    "```\n",
    "\n",
    "**Grading** \n",
    "\n",
    "You will receive points for the correct functions (doc string, definition, and correct output), the print statements, and the script(s). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6939cd2d",
   "metadata": {},
   "source": [
    "**Recommended helper functions**\n",
    "\n",
    "We highly recommend definining small helper functions that extract information from a single talk element. \n",
    "\n",
    "First think about the different pieces of information you will need:\n",
    "\n",
    "* talk id\n",
    "* date (attention: use `date` rather than `dtime`)\n",
    "* title\n",
    "* speaker\n",
    "* word count (already counted for you; you do not have to use the text for this\n",
    "\n",
    "In addition, you want to load your file as an xml tree, access the root and extract all talks (as a list of xml elements). Tip: Use one element in the list to develop and test your helper functions. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3c28090",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example:\n",
    "\n",
    "def load_root(path):\n",
    "    \"\"\"Find the root of an xml file given a filepath (str). \"\"\"\n",
    "    tree = et.parse(path)\n",
    "    root = tree.getroot()\n",
    "    return root\n",
    "\n",
    "def get_talks(root):\n",
    "    \"\"\"Get all talk elements from an xml file.\"\"\"\n",
    "    talks = root.findall('file')\n",
    "    return talks\n",
    "\n",
    "path = '../Data/ted-talks/XML_releases/xml/ted_en-20160408.xml'\n",
    "root = load_root(path)\n",
    "talks = get_talks(root)\n",
    "\n",
    "print(len(talks))\n",
    "\n",
    "# This can be your test example\n",
    "test_talk = talks[3]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f5a56b2",
   "metadata": {},
   "source": [
    "# Part II: Analyze the translations\n",
    "\n",
    "This part of the assignment requires you to compare information accross multiple files. \n",
    "\n",
    "* Which language has the most translations? Which language has the least translations?\n",
    "\n",
    "* Which talk(s) is (are) translated into most languages? Please provide the English title(s) and the talk ids. \n",
    "\n",
    "* BONUS (just for fun - no points): What is the word for 'applaus' in the languages represented in the corpus?\n",
    "\n",
    "\n",
    "Please create a script called `ted_translation_analysis.py`. The script should print answers to the questions above. You can reuse (import, copy, modify) functions you created for Part I. \n",
    "\n",
    "Below, you will find several steps that guide you through the assignment. Code following these steps will earn you points (even if you do not manage to get the correct final output)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4df42843",
   "metadata": {},
   "source": [
    "### Step 1. Map languages to filepaths \n",
    "\n",
    "Answering the questions above will require you to load and analyze xml files containing the translations of the English talks. It will be useful to have a dictionary that maps languages to filepaths. For example, the dictionary should contain the following entries: \n",
    "\n",
    "```\n",
    "{\n",
    "    'nl' :  '../Data/ted-talks/FILTERED_xml/ted_nl.xml',\n",
    "    'it' : '../Data/ted-talks/FILTERED_xml/ted_it.xml',\n",
    "    'fr-ca': '../Data/ted-talks/FILTERED_xml/ted_fr-ca.xml',\n",
    "    ...\n",
    "}\n",
    "```\n",
    "You can use the os or glob package to get a list of all filepaths in the directory `../Data/ted-talks/FILTERED_xml`. Note that the language is provided after `ted_`. Use string manipulation to access the language information. Attention: Some languages contain a hyphen (e.g. Canadian French fr-ca). \n",
    "\n",
    "In this assignment, you do not have to spell out the languages. It is alright if you provide the shortened names as they appear in the filepaths. \n",
    "\n",
    "Write a function (called `map_languages_to_paths`) that returns the dictionary. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c7f2c41",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fr-ca\n"
     ]
    }
   ],
   "source": [
    "# Example string manipulation (feel free to choose a different strategy)\n",
    "path = '../Data/ted-talks/FILTERED_xml/ted_fr-ca.xml'\n",
    "name = path.split('/')[-1].strip('.xml')\n",
    "lang = name.split('_')[1]\n",
    "print(lang)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6a1ad44",
   "metadata": {},
   "source": [
    "### Step 2: Write a function which returns the language with the most/least translations\n",
    "\n",
    "Name: `find_coverage`\n",
    "\n",
    "Input:\n",
    "\n",
    "* dictionary mapping languages to paths (positional)\n",
    "* most/least languages (e.g. 'most', 'least') (positional) \n",
    "\n",
    "Output: \n",
    "\n",
    "* a dictionary with language(s) (keys) and the respective number of tranlated talks (values)\n",
    "\n",
    "\n",
    "Tip: You can simply check the number of talks in each xml file corresponding to a language. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cc9d752",
   "metadata": {},
   "source": [
    "### Step 3: Map talk ids to titles\n",
    "\n",
    "You can use talk ids to map English talks to their translations in other languages. Most of your code will work with these ids. In the end, you should map talk ids to titles. \n",
    "\n",
    "Write a function called `get_id_title_dict` that maps talk ids to English titles. Your function should take the path to the English file as input and return a dictionary (keys: talk ids, values: English talk titles). \n",
    "\n",
    "Tip: Reuse functions from the previous assignment. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd93215b",
   "metadata": {},
   "source": [
    "### Step 4 Map talks to languages they have been translated into\n",
    "\n",
    "Function name: Map_talks_to_languages\n",
    "\n",
    "Input: language filepath dict (result of Step 1)\n",
    "\n",
    "Output: a dictionary mapping talk ids to languages with translations of the talk. The dictionary should have the following structure (the example is made up):\n",
    "\n",
    "```\n",
    "{\n",
    "    '10': ['hy', 'nl', 'de', 'fr-ca']\n",
    "    '20': ['pl', 'da', 'nl', 'oc', 'ar']\n",
    "\n",
    "}\n",
    "\n",
    "```\n",
    "    \n",
    "    \n",
    "Tip: You can use defaultdict for this step."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ba85b0",
   "metadata": {},
   "source": [
    "### Step 5: Map number of languages to talks\n",
    "\n",
    "Goal: You want to know which talks haven been translated into how many languages. In the next step, you will want to rank talks by how many languages they've been translated into (or directly get the highest or lowest number of translations). To do this, it is useful to have a mapping from the number of translations to the talk ids\n",
    "\n",
    "Function name: map_nlang_to_talks\n",
    "\n",
    "Input: dictionary mapping talk ids to languages (list)\n",
    "\n",
    "Output: dictionary mapping number of translations (int) to talks (list of talk ids) having the following structure (this is not the correct output - just an example of the structure):\n",
    "\n",
    "```\n",
    "{\n",
    "\n",
    "    30 : ['200', '10', '31']\n",
    "    29 : ['201', '9', '7']\n",
    "    47 : ['1', '14', '209', '5']\n",
    "\n",
    "}\n",
    "\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dfa501b",
   "metadata": {},
   "source": [
    "### Step 6: Put it all together\n",
    "\n",
    "Put the functions you wrote above together to find the talk(s) that has (have) been translated into the most or least languages\n",
    "\n",
    "Name: find_top_coverage\n",
    "\n",
    "Input: \n",
    "    * dict mapping languages to filepaths (created in Step 1)\n",
    "    * most or least translations ('most' or 'least')\n",
    "    \n",
    "Output: A dictionary mapping the most/least talk titles to the languages they have been translated into. For example (this is not the correct solution - we just use it to show the structure):\n",
    "\n",
    "```\n",
    "{\n",
    "    'Dan Gross: Why gun violence can't be our new normal' : ['de', 'nl', 'it']\n",
    "    'Ang√©lica Dass: The beauty of human skin in every color': ['fr-ca', 'de', 'ceb']\n",
    "\n",
    "\n",
    "}\n",
    "```\n",
    "\n",
    "Use the output to print the correct solution to the terminal. (Tip: Call the same function twice - once for the most translations, once for the least translations)\n",
    "    \n",
    "    \n",
    "**Code structure:**\n",
    "\n",
    "Your functions should be called in the script called `ted_translation_analysis.py`. If you used helper functions (recommended), please store them in utils.py and import them. \n",
    "\n",
    "**Informative print statements**\n",
    "\n",
    "Please add print statements so the output can be interpreted. See instructions for Part 1. \n",
    "\n",
    "\n",
    "**Grading**\n",
    "\n",
    "You will receive points for the functions,  the print statements, and the script. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18bdafd",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
