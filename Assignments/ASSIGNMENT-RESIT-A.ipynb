{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resit Assignment part A\n",
    "\n",
    "**Deadline: Tuesday, November 30, 2021 before 17:00** \n",
    "\n",
    "- Please name your files: \n",
    "    * ASSIGNMENT-RESIT-A.ipynb\n",
    "    * utils.py (from part B)\n",
    "    * raw_text_to_coll.py (from part B)\n",
    "\n",
    "Please name your zip file as follows: RESIT-ASSIGNMENT.zip and upload it via Canvas (Resit Assignment). \n",
    "- Please submit your assignment on Canvas: Resit Assignment\n",
    "- If you have **questions** about this topic, please use the Python Teacher mailing list (cltl.python.course@gmail.com).\n",
    "**Note that we currently only check this mailing list once a day. We have given a week extra time, so please start timely.**\n",
    "    \n",
    "Answers to general questions will be covered on Piazza (https://piazza.com/class/kt1o9ir48ph50c), so please check if your question has already been answered.\n",
    "\n",
    "All of the covered chapters are important to this assignment. However, please pay special attention to:\n",
    "- Chapter 10 - Dictionaries\n",
    "- Chapter 11 - Functions and scope\n",
    "* Chapter 14 - Reading and writing text files\n",
    "* Chapter 15 - Off to analyzing text \n",
    "- Chapter 17 - Data Formats II (JSON)\n",
    "- Chapter 19 - More about Natural Language Processing Tools (spaCy)\n",
    "\n",
    "\n",
    "In this assignment:\n",
    "* we are going to process the texts in ../Data/Dreams/*txt\n",
    "* for each file, we are going to determine:\n",
    "    * the number of characters\n",
    "    * the number of sentences\n",
    "    * the number of words\n",
    "    * the longest word\n",
    "    * the longest sentence"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Note\n",
    "This notebook should be placed in the same folder as the other Assignments!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading spaCy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure that spaCy is installed on your computer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please make sure you can load the English spaCy model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 1: get paths"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function called **get_paths** that has the following parameter: \n",
    "* **input_folder**: a string\n",
    "\n",
    "The function:\n",
    "* stores all paths to .txt files in the *input_folder* in a list\n",
    "* returns a list of strings, i.e., each string is a file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please test your function using the following function call"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "paths = get_paths(input_folder='../Data/Dreams')\n",
    "print(paths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 2: load text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function called **load_text** that has the following parameter: \n",
    "* **txt_path**: a string\n",
    "\n",
    "\n",
    "The function:\n",
    "* opens the **txt_path** for reading and loads the contents of the file as a string\n",
    "* returns a string, i.e., the content of the file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 3: return the longest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function called **return_the_longest** that has the following parameter: \n",
    "* **list_of_strings**: a list of strings\n",
    "\n",
    "\n",
    "The function:\n",
    "* returns the string with the highest number of characters. If multiple strings have the same length, return one of them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def return_the_longest(list_of_strings):\n",
    "    \"\"\"\n",
    "    given a list of strings, return the longest string\n",
    "    if multiple strings have the same length, return one of them.\n",
    "    \n",
    "    :param str list_of_strings: a list of strings\n",
    "    \n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Please test you function by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_list_of_strings = [\"this\", \"is\", \"a\", \"sentence\"]\n",
    "longest_string = return_the_longest(a_list_of_strings)\n",
    "\n",
    "error_message = f'the longest string should be \"sentence\", you provided {longest_string}'\n",
    "assert longest_string == 'sentence', error_message"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 4: extract statistics\n",
    "We are going to use spaCy to extract statistics from Vickie's dreams! Here are a few tips below about how to use spaCy:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tip 1: process text with spaCy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_text = 'this is one sentence. this is another.'\n",
    "doc = nlp(a_text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tip 2: the number of characters is the length of the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chars = len(doc.text)\n",
    "print(num_chars)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tip 3: loop through the sentences of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sent in doc.sents:\n",
    "    sent = sent.text\n",
    "    print(sent)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tip 4: loop through the words of a document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    word = token.text\n",
    "    print(word)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function called **extract_statistics** that has the following parameters: \n",
    "* **nlp**: the result of calling spacy.load('en_core_web_sm')\n",
    "* **txt_path**: path to a txt file, e.g., '../Data/Dreams/vickie8.txt'\n",
    "\n",
    "The function:\n",
    "* loads the content of the file using the function **load_text**\n",
    "* processes the content of the file using **nlp(content)** (see tip 1 of this exercise)\n",
    "\n",
    "The function returns a dictionary with five keys:\n",
    "* **num_sents**: the number of sentences in the document\n",
    "* **num_chars**: the number of characters in the document\n",
    "* **num_tokens**: the number of words in the document\n",
    "* **longest_sent**: the longest sentence in the document\n",
    "    * Please make a list with all the sentences and call the function **return_the_longest** to retrieve the longest sentence\n",
    "* **longest_word**: the longest word in the document\n",
    "    * Please make a list with all the words and call the function **return_the_longest** to retrieve the longest word\n",
    "    \n",
    "Test the function on one of the files from Vickie's dreams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_statistics(nlp, txt_path):\n",
    "    \"\"\"\n",
    "    given a txt_path\n",
    "    -use the load_text function to load the text\n",
    "    -process the text using spaCy\n",
    "    \n",
    "    :param nlp: loaded spaCy model (result of calling spacy.load('en_core_web_sm'))\n",
    "    :param str txt_path: path to txt file\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: a dictionary with the following keys:\n",
    "    -\"num_sents\" : the number of sentences\n",
    "    -\"num_chars\" : the number of characters \n",
    "    -\"num_tokens\" : the number of words \n",
    "    -\"longest_sent\" : the longest sentence\n",
    "    -\"longest_word\" : the longest word\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stats = extract_statistics(nlp, txt_path=paths[0])\n",
    "stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 5: process all txt files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### tip 1: how to obtain the basename of a file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename = os.path.basename('../Data/Dreams/vickie1.txt')[:-4]\n",
    "print(basename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define a function called **process_all_txt_files** that has the following parameters: \n",
    "* **nlp**: the result of calling spacy.load('en_core_web_sm')\n",
    "* **input_folder**: a string (we will test it using '../Data/Dreams')\n",
    "\n",
    "The function:\n",
    "* obtains a list of txt paths using the function **get_paths** with **input_folder** as an argument\n",
    "* loops through the txt paths one by one\n",
    "* for each iteration, the **extract_statistics** function is called with **txt_path** as an argument\n",
    "\n",
    "The function returns a dictionary:\n",
    "* the keys are the basenames of the txt files (see tip 1 of this exercise)\n",
    "* the values are the output of calling the function **extract_statistics** for a specific file\n",
    "\n",
    "Test your function using '../Data/Dreams' as a value for the parameter *input_folder*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_all_txt_files(nlp, input_folder):\n",
    "    \"\"\"\n",
    "    given a list of txt_paths\n",
    "    -process each with the extract_statistics function\n",
    "    \n",
    "    :param nlp: loaded spaCy model (result of calling spacy.load('en_core_web_sm'))\n",
    "    :param list txt_paths: list of paths to txt files\n",
    "    \n",
    "    :rtype: dict\n",
    "    :return: dictionary mapping:\n",
    "    -basename -> output of extract_statistics function\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "basename_to_stats = process_all_txt_files(nlp, input_folder='../Data/Dreams')\n",
    "basename_to_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise 6: write to disk"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this exercise, you are going to write our results to our computer.\n",
    "Please loop through **basename_to_stats** and create one JSON file for each dream.\n",
    "\n",
    "* the path is f'{basename}.json', i.e., 'vickie1.json', 'vickie2.json', etc. (please write them to the same folder as this notebook)\n",
    "* the content of each JSON file is each value of **basename_to_stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for basename, stats in basename_to_stats.items():\n",
    "    pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
